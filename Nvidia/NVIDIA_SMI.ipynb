{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04dSVwpKKC9T",
        "outputId": "00d1a9ec-09a3-4410-fd20-a7f0941f76b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxElOlElJmf1"
      },
      "outputs": [],
      "source": [
        "import groq\n",
        "\n",
        "# Initialize Groq API client\n",
        "client = groq.Client(api_key=\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to demonstrate Chain of Thought (CoT)\n",
        "def chain_of_thought_example():\n",
        "    prompt = \"\"\"\n",
        "    Let's solve this math problem step by step:\n",
        "    If a train travels at 80 km/h for 3 hours, how far does it travel?\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-8b-8192\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant that follows the Chain of Thought process.\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "upKYN0SRKUTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to demonstrate ReAct (Reasoning + Acting)\n",
        "def react_example():\n",
        "    prompt = \"\"\"\n",
        "    You are an AI agent that first reasons, then acts. Answer this question step by step:\n",
        "    Who won the FIFA World Cup in 2022?\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-8b-8192\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are an AI agent using the ReAct approach.\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "FPIne7SxKXRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to demonstrate Reflection\n",
        "def reflection_example():\n",
        "    initial_prompt = \"Write a short story about a brave cat.\"\n",
        "    initial_response = client.chat.completions.create(\n",
        "        model=\"llama3-8b-8192\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are a creative storyteller.\"},\n",
        "                  {\"role\": \"user\", \"content\": initial_prompt}]\n",
        "    )\n",
        "    story = initial_response.choices[0].message.content\n",
        "\n",
        "    # AI Reflecting on its own story and improving it\n",
        "    reflection_prompt = f\"Improve the following story by adding more depth and creativity: {story}\"\n",
        "    improved_response = client.chat.completions.create(\n",
        "        model=\"llama3-8b-8192\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are an AI that reflects on previous responses and improves them.\"},\n",
        "                  {\"role\": \"user\", \"content\": reflection_prompt}]\n",
        "    )\n",
        "    return improved_response.choices[0].message.content\n",
        "\n",
        "# Additional function to test various aspects\n",
        "def test_all_concepts():\n",
        "    print(\"\\n=== Chain of Thought Example ===\")\n",
        "    print(chain_of_thought_example())\n",
        "\n",
        "    print(\"\\n=== ReAct Example ===\")\n",
        "    print(react_example())\n",
        "\n",
        "    print(\"\\n=== Reflection Example ===\")\n",
        "    print(reflection_example())\n",
        "\n",
        "    print(\"\\n=== Testing Multi-Step Reasoning ===\")\n",
        "    multi_step_prompt = \"\"\"\n",
        "    A farmer has 10 apples. He gives away 3 apples to his friend and then buys 5 more apples.\n",
        "    How many apples does he have now? Solve this step by step.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-8b-8192\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"Solve the problem step by step using logical reasoning.\"},\n",
        "                  {\"role\": \"user\", \"content\": multi_step_prompt}]\n",
        "    )\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "    print(\"\\n=== Testing Decision Making and Planning ===\")\n",
        "    planning_prompt = \"\"\"\n",
        "    Imagine you are an AI assistant helping a user plan a one-week trip to Japan.\n",
        "    Provide a detailed itinerary including places to visit, food recommendations, and estimated travel costs.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-8b-8192\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are an expert travel planner.\"},\n",
        "                  {\"role\": \"user\", \"content\": planning_prompt}]\n",
        "    )\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "# Running and validating outputs\n",
        "if __name__ == \"__main__\":\n",
        "    test_all_concepts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Xn4qsNKbMO",
        "outputId": "b047bfef-6125-406b-a2f5-b6b03231a106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Chain of Thought Example ===\n",
            "Sounds like a fun problem!\n",
            "\n",
            "To solve this problem, I'll follow the Chain of Thought process. Here's my thought process:\n",
            "\n",
            "1. The problem gives us the train's speed: 80 km/h.\n",
            "2. The problem also gives us the time the train travels: 3 hours.\n",
            "3. We need to find out how far the train travels.\n",
            "\n",
            "To find the distance traveled, I'll multiply the speed (80 km/h) by the time (3 hours).\n",
            "\n",
            "4. I'll multiply 80 km/h by 3 hours:\n",
            "\n",
            "80 km/h × 3 hours = ?\n",
            "\n",
            "Now, let me calculate...\n",
            "\n",
            "5. The result of the multiplication is:\n",
            "\n",
            "80 km/h × 3 hours = 240 km\n",
            "\n",
            "So, the train travels 240 km in 3 hours!\n",
            "\n",
            "The answer is: 240 km\n",
            "\n",
            "=== ReAct Example ===\n",
            "A question that requires reasoning and then acting!\n",
            "\n",
            "**Reasoning:**\n",
            "To answer this question, I need to use my knowledge database and reasoning capabilities. I will search for information related to the FIFA World Cup in 2022 and try to find the answer.\n",
            "\n",
            "**Fact-finding:**\n",
            "After searching my database, I found that the FIFA World Cup in 2022 was held in Qatar from November 20 to December 18, 2022. I also found that Argentina won the tournament by defeating France 4-2 in the final.\n",
            "\n",
            "**Inference:**\n",
            "Based on the information I found, I can confidently conclude that Argentina won the FIFA World Cup in 2022.\n",
            "\n",
            "**Action:**\n",
            "Now that I have reasoned and concluded the answer, I will act by stating the answer to your question:\n",
            "\n",
            "**Answer:** Argentina won the FIFA World Cup in 2022.\n",
            "\n",
            "=== Reflection Example ===\n",
            "Here is an improved version of the story with added depth and creativity:\n",
            "\n",
            "Whiskers, the sleek and agile feline with shimmering gray fur and piercing green eyes, was known for her fearless spirit. She lived in a cozy little house on a quiet street, surrounded by lush gardens and towering trees that seemed to stretch up to the sky, their leaves whispering secrets to each other in the gentle breeze. The scent of blooming flowers and fresh rain filled the air, and Whiskers loved nothing more than to lounge on the windowsill, watching the world go by.\n",
            "\n",
            "But one sweltering summer afternoon, disaster struck. A massive storm rolled in, bringing with it strong winds that howled like wolves, heavy rain that pounded against the pavement like a thousand tiny drummers, and flashes of lightning that illuminated the darkening sky with a blinding intensity. The neighbors' dogs began to bark and whine, sensing the chaos, and Whiskers' human family huddled together in fear, their voices trembling with uncertainty.\n",
            "\n",
            "Whiskers, however, was not one to cower in fear. She recognized the danger that lurked in every creaking tree branch and snapping power line, and she knew that someone had to act. So, with her tail held high and her ears pointed forward, she steeled herself for the task ahead.\n",
            "\n",
            "She slipped out into the storm, her paws skidding on the slick pavement as she made her way through the torrential rain. The wind buffeted her, trying to knock her off her feet, but Whiskers dug her claws into the ground and pushed on, her eyes fixed on the task at hand.\n",
            "\n",
            "First, she stalked through the rain-soaked garden, her paws splashing in puddles as she examined every inch of the landscape. She spotted a loose fence board, half-blown open by the gusts, and with a swift swipe of her paw, she slammed it shut, securing the safety of her home. The neighbors' dogs, sensing the bravery of their feline friend, ceased their barking and whining, and instead watched her with wide, admiring eyes.\n",
            "\n",
            "Next, she set her sights on the ancient oak tree, whose branches creaked and groaned in the wind like an orchestra of dying giants. Whiskers climbed up, her claws digging into the wet bark, and settled on a sturdy branch, her eyes fixed on the swaying limbs. As the storm intensified, she batted at the wind-beaten leaves, using her agility and quick reflexes to stabilize the tree and keep it from crashing to the ground. The tree creaked and groaned in gratitude, its branches swaying in time with Whiskers' gentle nudges.\n",
            "\n",
            "Meanwhile, back at the house, the family watched in amazement as Whiskers bravely battled the storm. They cheered and clapped, urging her on as she fearlessly dodged the raindrops and lightning flashes. The neighbors, drawn out of their homes by the commotion, gathered at the front fence, mesmerized by the tiny figure in the storm.\n",
            "\n",
            "When the storm finally began to subside, Whiskers descended from the tree, her fur fluffed and ruffled, but her eyes shining with a fierce inner light. The family cheered and clapped, showering her with treats and belly rubs. The neighbors, moved by her bravery, petted and praised her, and the other animals looked up to her as a symbol of courage and determination.\n",
            "\n",
            "From that day on, Whiskers was hailed as a hero in the neighborhood. The family celebrated her bravery with a grand feast, and the story of her courageous exploits was passed down from generation to generation. And though the storm had been fierce, Whiskers had tamed it, proving that even the smallest creature can make a big impact when given the chance.\n",
            "\n",
            "=== Testing Multi-Step Reasoning ===\n",
            "Let's break it down step by step:\n",
            "\n",
            "1. The farmer starts with 10 apples.\n",
            "2. He gives away 3 apples to his friend. To find the number of apples he has left, we subtract 3 from 10:\n",
            "\n",
            "10 - 3 = 7\n",
            "\n",
            "So, the farmer has 7 apples left.\n",
            "\n",
            "3. Then, he buys 5 more apples. To find the total number of apples he now has, we add 5 to the 7 apples he already had:\n",
            "\n",
            "7 + 5 = 12\n",
            "\n",
            "Therefore, the farmer now has 12 apples.\n",
            "\n",
            "=== Testing Decision Making and Planning ===\n",
            "Japan! A country of vibrant culture, rich history, and breathtaking natural beauty. I'd be delighted to help you plan an unforgettable one-week trip to this amazing land.\n",
            "\n",
            "**Day 1: Arrival in Tokyo**\n",
            "\n",
            "* Arrive at Haneda Airport (TYO) and take a bus or train to your hotel\n",
            "* Check-in at a hotel in Shinjuku or Shibuya ( approx. ¥25,000 - ¥35,000 / $230-$320 USD per night)\n",
            "* Spend the afternoon exploring the trendy Shibuya area, visit the famous Shibuya Crossing, and take a stroll around the nearby Yoyogi Park\n",
            "* For dinner, try a classic Tokyo-style noodle dish at Totto Ramen ( approx. ¥800 - ¥1,200 / $7-$10 USD per person)\n",
            "\n",
            "**Day 2: Tokyo**\n",
            "\n",
            "* Start the day with a visit to the Tokyo Skytree for a panoramic view of the city (¥2,060 / $19 USD per person)\n",
            "* Explore the Nezu Museum, which boasts a beautiful garden and an impressive collection of Japanese art (¥2,000 / $18 USD per person)\n",
            "* Visit the famous Tsukiji Fish Market, even if you're not a fan of seafood, for a unique experience (free admission)\n",
            "* Enjoy a delicious tonkatsu dinner at Aoi ( approx. ¥5,000 - ¥7,000 / $45-$65 USD per person)\n",
            "\n",
            "**Day 3: Nikko**\n",
            "\n",
            "* Take a day trip to Nikko, a UNESCO World Heritage site located about 2 hours away from Tokyo ( approx. ¥10,000 - ¥15,000 / $90-$140 USD per person, including transportation and entrance fees)\n",
            "* Visit the magnificent Toshogu Shrine, a stunning example of Japanese architecture (¥1,300 / $12 USD per person)\n",
            "* Explore the nearby Rinno-ji Temple and Futarasan Shrine (combined entrance fee: ¥600 / $5 USD per person)\n",
            "\n",
            "**Day 4: Travel to Kyoto**\n",
            "\n",
            "* Take the bullet train (Shinkansen) to Kyoto ( approx. ¥14,000 - ¥20,000 / $130-$180 USD per person, one way)\n",
            "* Check-in at a hotel in Gion or Kyoto Station ( approx. ¥20,000 - ¥30,000 / $180-$260 USD per night)\n",
            "* Visit the famous Kinkaku-ji Temple (Golden Pavilion) in the afternoon (¥500 / $4.50 USD per person)\n",
            "* Enjoy a traditional Kyoto-style kaiseki dinner at Gion Nanba ( approx. ¥10,000 - ¥15,000 / $90-$140 USD per person)\n",
            "\n",
            "**Day 5: Kyoto**\n",
            "\n",
            "* Visit the Fushimi Inari Shrine, famous for its thousands of vermilion torii gates (free admission)\n",
            "* Explore the Kiyomizu-dera Temple, a UNESCO World Heritage site and one of Kyoto's most iconic landmarks (¥500 / $4.50 USD per person)\n",
            "* Visit the Nijo Castle, built for the Tokugawa shoguns (¥600 / $5.50 USD per person)\n",
            "* Enjoy a delicious yudofu dinner at Yudofu Sagano ( approx. ¥3,000 - ¥5,000 / $27-$45 USD per person)\n",
            "\n",
            "**Day 6: Nara**\n",
            "\n",
            "* Take a day trip to Nara, another ancient city located about 1 hour away from Kyoto ( approx. ¥1,000 - ¥2,000 / $9-$18 USD per person, including transportation and entrance fees)\n",
            "* Visit the Todai-ji Temple, home to the largest bronze Buddha statue in the world (¥500 / $4.50 USD per person)\n",
            "* Explore the Nara Park, a large park that is home to over 1,000 wild deer (free admission)\n",
            "\n",
            "**Day 7: Departure from Osaka**\n",
            "\n",
            "* Take the train to Osaka ( approx. ¥400 - ¥1,000 / $3.60-$9 USD per person, one way)\n",
            "* Spend the morning shopping for last-minute souvenirs or exploring the Dotonbori area\n",
            "* Depart from Kansai International Airport (KIX) for your return journey\n",
            "\n",
            "**Estimated Travel Costs:**\n",
            "\n",
            "* Airfare from your home country to Haneda Airport in Tokyo: ¥100,000 - ¥200,000 / $900-$1,800 USD per person (depending on the airline and time of year)\n",
            "* Accommodation: ¥150,000 - ¥250,000 / $1,350-$2,250 USD per person for 7 nights\n",
            "* Transportation: ¥40,000 - ¥80,000 / $360-$720 USD per person for train tickets, buses, and taxis\n",
            "* Food and drink: ¥30,000 - ¥50,000 / $270-$450 USD per person for meals and snacks\n",
            "* Entrance fees and attractions: ¥10,000 - ¥20,000 / $90-$180 USD per person\n",
            "* Total estimated cost: ¥340,000 - ¥590,000 / $3,060-$5,310 USD per person\n",
            "\n",
            "**Tips and Recommendations:**\n",
            "\n",
            "* Consider purchasing a Japan Rail Pass for your train travel, which can save you a significant amount of money.\n",
            "* Try to avoid visiting popular attractions during peak hours (usually between 11am and 3pm) to avoid long queues.\n",
            "* Don't be afraid to try new foods and drinks, as Japan has a unique and delicious culinary scene.\n",
            "* Learn some basic Japanese phrases, such as hello (konnichiwa), thank you (arigatou), and excuse me (sumimasen), to show respect for the culture.\n",
            "* Be prepared for crowds and lines at popular tourist spots, and plan your itinerary accordingly.\n",
            "\n",
            "I hope this itinerary helps you plan an unforgettable trip to Japan!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import time\n",
        "\n",
        "# Memory to store tasks (our \"state\")\n",
        "task_list = {}\n",
        "\n",
        "# Intent detection function\n",
        "def detect_intent(user_input):\n",
        "    user_input = user_input.lower().strip()\n",
        "\n",
        "    # Define simple intent rules using regex and keywords\n",
        "    if re.search(r'add|create|new', user_input):\n",
        "        return \"add_task\"\n",
        "    elif re.search(r'list|show|view', user_input):\n",
        "        return \"list_tasks\"\n",
        "    elif re.search(r'remove|delete|clear', user_input):\n",
        "        return \"remove_task\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "# Entity extraction function\n",
        "def extract_entities(user_input):\n",
        "    user_input = user_input.lower().strip()\n",
        "    entities = {}\n",
        "\n",
        "    # Extract task name (simple: assume it's after \"add\" or \"task\")\n",
        "    task_match = re.search(r'(add|task)\\s+(.+?)(?:\\s+at|\\s+on|$)', user_input)\n",
        "    if task_match:\n",
        "        entities['task_name'] = task_match.group(2).strip()\n",
        "\n",
        "    # Extract time (e.g., \"at 3pm\" or \"on Monday\")\n",
        "    time_match = re.search(r'(at|on)\\s+(.+?)(?:\\s+|$)', user_input)\n",
        "    if time_match:\n",
        "        entities['time'] = time_match.group(2).strip()\n",
        "\n",
        "    return entities\n",
        "\n",
        "# Action handlers\n",
        "def add_task(entities):\n",
        "    if 'task_name' not in entities:\n",
        "        return \"Sorry, I didn’t catch the task name. What would you like to add?\"\n",
        "\n",
        "    task_name = entities['task_name']\n",
        "    task_id = str(time.time())  # Unique ID based on timestamp\n",
        "    task_list[task_id] = {\n",
        "        'name': task_name,\n",
        "        'time': entities.get('time', 'unspecified')\n",
        "    }\n",
        "    return f\"Added task: '{task_name}' (Time: {task_list[task_id]['time']})\"\n",
        "\n",
        "def list_tasks():\n",
        "    if not task_list:\n",
        "        return \"You don’t have any tasks yet!\"\n",
        "\n",
        "    response = \"Your tasks:\\n\"\n",
        "    for task_id, task in task_list.items():\n",
        "        response += f\"- {task['name']} (Time: {task['time']})\\n\"\n",
        "    return response.strip()\n",
        "\n",
        "def remove_task(entities):\n",
        "    if 'task_name' not in entities:\n",
        "        return \"Which task would you like to remove?\"\n",
        "\n",
        "    task_name = entities['task_name']\n",
        "    for task_id, task in list(task_list.items()):\n",
        "        if task['name'].lower() == task_name:\n",
        "            del task_list[task_id]\n",
        "            return f\"Removed task: '{task_name}'\"\n",
        "    return f\"Couldn’t find task: '{task_name}'\"\n",
        "\n",
        "# Response generation\n",
        "def generate_response(intent, entities):\n",
        "    if intent == \"add_task\":\n",
        "        return add_task(entities)\n",
        "    elif intent == \"list_tasks\":\n",
        "        return list_tasks()\n",
        "    elif intent == \"remove_task\":\n",
        "        return remove_task(entities)\n",
        "    else:\n",
        "        return \"Sorry, I didn’t understand that. I can add, list, or remove tasks. How can I help?\"\n",
        "\n",
        "# Main agent loop\n",
        "def run_agent():\n",
        "    print(\"Hello! I’m your Task Assistant. How can I help you today?\")\n",
        "    while True:\n",
        "        user_input = input(\"> \")\n",
        "        if user_input.lower() in ['exit', 'quit']:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Process input\n",
        "        intent = detect_intent(user_input)\n",
        "        entities = extract_entities(user_input)\n",
        "        response = generate_response(intent, entities)\n",
        "        print(response)\n",
        "\n",
        "# Start the agent\n",
        "if __name__ == \"__main__\":\n",
        "    run_agent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "1TYj-XPhKffi",
        "outputId": "14e078f4-a7de-4a61-8498-2ec5f283fade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I’m your Task Assistant. How can I help you today?\n",
            "> hi\n",
            "Sorry, I didn’t understand that. I can add, list, or remove tasks. How can I help?\n",
            "> hi tehre\n",
            "Sorry, I didn’t understand that. I can add, list, or remove tasks. How can I help?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ae1b1c6bc2fb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# Start the agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mrun_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-ae1b1c6bc2fb>\u001b[0m in \u001b[0;36mrun_agent\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello! I’m your Task Assistant. How can I help you today?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# 1️⃣ Check GPU availability\n",
        "gpu_available = torch.cuda.is_available()\n",
        "print(f\"✅ GPU Available: {gpu_available}\")\n",
        "\n",
        "# 2️⃣ Check CUDA version\n",
        "cuda_version = torch.version.cuda\n",
        "print(f\"✅ CUDA Version: {cuda_version}\")\n",
        "\n",
        "# 3️⃣ Check cuDNN version\n",
        "cudnn_version = torch.backends.cudnn.version()\n",
        "print(f\"✅ cuDNN Version: {cudnn_version}\")\n",
        "\n",
        "# 4️⃣ Check TensorFlow GPU support\n",
        "print(f\"✅ TensorFlow GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# 5️⃣ Run NVIDIA-SMI\n",
        "!nvidia-smi\n",
        "\n",
        "# 6️⃣ Check environment variables (CUDA paths)\n",
        "print(f\"✅ CUDA Path: {os.environ.get('CUDA_PATH')}\")\n",
        "print(f\"✅ LD_LIBRARY_PATH: {os.environ.get('LD_LIBRARY_PATH')}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PmmyqWTQXUT",
        "outputId": "fcd2e5c6-1eac-48fe-c252-df79c8d234e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GPU Available: True\n",
            "✅ CUDA Version: 12.4\n",
            "✅ cuDNN Version: 90300\n",
            "✅ TensorFlow GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Tue Mar 11 10:08:39 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "✅ CUDA Path: None\n",
            "✅ LD_LIBRARY_PATH: /usr/local/lib/python3.11/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## 5️⃣ Test GPU Performance Using PyTorch (Matrix Multiplication)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "a = torch.randn(1000, 1000, device=device)\n",
        "b = torch.randn(1000, 1000, device=device)\n",
        "%time c = torch.matmul(a, b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6iF8YsRrV3r",
        "outputId": "2b7cea90-6f0b-4c0c-e4d4-6dc740211d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 34.1 ms, sys: 14.2 ms, total: 48.3 ms\n",
            "Wall time: 202 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 6️⃣ Test GPU Performance Using TensorFlow (Matrix Multiplication)\n",
        "with tf.device('/GPU:0'):\n",
        "    A = tf.random.normal([1000, 1000])\n",
        "    B = tf.random.normal([1000, 1000])\n",
        "    %time C = tf.matmul(A, B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjXaLZkMsYLI",
        "outputId": "0b94ebee-e66d-4529-ade6-ddcfb66a2a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.07 ms, sys: 12 µs, total: 2.08 ms\n",
            "Wall time: 2.26 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 7️⃣ Interfacing with Groq API for AI Processing\n",
        "import requests\n",
        "import json\n",
        "\n",
        "API_URL = \"https://api.groq.com/v1/chat/completions\"\n",
        "HEADERS = {\"Authorization\": \"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\", \"Content-Type\": \"application/json\"}\n",
        "\n",
        "def chat_with_groq(prompt):\n",
        "    payload = {\n",
        "        \"model\": \"llama3-8b-8192\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "    }\n",
        "    response = requests.post(API_URL, headers=HEADERS, data=json.dumps(payload))\n",
        "    return response.json()\n",
        "\n",
        "# Example Query to Groq API\n",
        "response = chat_with_groq(\"Explain how CUDA accelerates deep learning models.\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrVWjN6Isdj8",
        "outputId": "53200de2-a6f1-4066-e49c-a9c46c4cabbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': {'message': 'Unknown request URL: POST /v1/chat/completions. Please check the URL for typos, or see the docs at https://console.groq.com/docs/', 'type': 'invalid_request_error', 'code': 'unknown_url'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## 5️⃣ GPU Performance Test - Large-Scale Matrix Multiplication\n",
        "# Testing GPU with Large Tensor Computation\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "a = torch.randn(5000, 5000, device=device)\n",
        "b = torch.randn(5000, 5000, device=device)\n",
        "%time c = torch.matmul(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEc5LBhGsk6K",
        "outputId": "0002e77b-d6d4-41af-a04e-4f310fb77711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 0 ns, sys: 541 µs, total: 541 µs\n",
            "Wall time: 563 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 6️⃣ AI Use Case - Deep Learning Model Training on GPU\n",
        "# Training a simple CNN model on CIFAR-10 dataset using PyTorch\n",
        "def train_cifar10():\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    import torchvision\n",
        "    import torchvision.transforms as transforms\n",
        "\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "    class Net(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Net, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(3, 32, 3, 1)  # Output: (32, 30, 30)\n",
        "            self.pool = nn.MaxPool2d(2, 2)       # Output: (32, 15, 15)\n",
        "            self.conv2 = nn.Conv2d(32, 64, 3, 1) # Output: (64, 13, 13)\n",
        "            self.pool2 = nn.MaxPool2d(2, 2)      # Output: (64, 6, 6)\n",
        "            self.fc1 = nn.Linear(64 * 6 * 6, 128)\n",
        "            self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = torch.relu(self.conv1(x))\n",
        "            x = self.pool(x)\n",
        "            x = torch.relu(self.conv2(x))\n",
        "            x = self.pool2(x)\n",
        "            x = torch.flatten(x, 1)  # Flatten before FC layers\n",
        "            x = torch.relu(self.fc1(x))\n",
        "            x = self.fc2(x)\n",
        "            return x\n",
        "\n",
        "    net = Net().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(1):  # Single epoch training for quick testing\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if i % 100 == 0:\n",
        "                print(f'Epoch [{epoch+1}], Step [{i}], Loss: {loss.item():.4f}')\n",
        "\n",
        "train_cifar10()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwH7e2sd1KDc",
        "outputId": "54137db8-7784-459a-cffc-7d34cbf3c108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Epoch [1], Step [0], Loss: 2.2964\n",
            "Epoch [1], Step [100], Loss: 1.5724\n",
            "Epoch [1], Step [200], Loss: 1.5463\n",
            "Epoch [1], Step [300], Loss: 1.5733\n",
            "Epoch [1], Step [400], Loss: 1.2153\n",
            "Epoch [1], Step [500], Loss: 1.1393\n",
            "Epoch [1], Step [600], Loss: 1.2246\n",
            "Epoch [1], Step [700], Loss: 1.3104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=memory.total,memory.used,memory.free --format=csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8FvqLEg1Ryy",
        "outputId": "1f2c5ad8-f525-4d25-c4e3-6426ab392d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "memory.total [MiB], memory.used [MiB], memory.free [MiB]\n",
            "15360 MiB, 576 MiB, 14518 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi pmon -i 0 -s um -c 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEwdHROB2tEV",
        "outputId": "78be5beb-354c-453a-b5df-96323424652d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=power.draw,power.limit,temperature.gpu --format=csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM2efYby3Zqu",
        "outputId": "8901c122-ab53-4cd8-a0bb-26aa3e881d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "power.draw [W], power.limit [W], temperature.gpu\n",
            "27.16 W, 70.00 W, 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab Notebook: NVIDIA Drivers, CUDA, cuDNN, and NVIDIA-SMI Analysis with AI Workloads\n",
        "\n",
        "## 1️⃣ Check NVIDIA GPU Availability and Specifications\n",
        "!nvidia-smi\n",
        "\n",
        "## 2️⃣ Verify CUDA Installation and Version\n",
        "import torch\n",
        "print(f\"✅ CUDA Available: {torch.cuda.is_available()}\")\n",
        "print(f\"✅ CUDA Version: {torch.version.cuda}\")\n",
        "\n",
        "## 3️⃣ Check cuDNN Installation\n",
        "print(f\"✅ cuDNN Version: {torch.backends.cudnn.version()}\")\n",
        "\n",
        "## 4️⃣ Verify TensorFlow GPU Support\n",
        "import tensorflow as tf\n",
        "print(f\"✅ TensorFlow GPU: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "## 5️⃣ GPU Performance Test - Large-Scale Matrix Multiplication\n",
        "# Testing GPU with Large Tensor Computation\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "a = torch.randn(5000, 5000, device=device)\n",
        "b = torch.randn(5000, 5000, device=device)\n",
        "%time c = torch.matmul(a, b)\n",
        "\n",
        "## 6️⃣ AI Use Case - Deep Learning Model Training on GPU\n",
        "# Training a simple CNN model on CIFAR-10 dataset using PyTorch\n",
        "def train_cifar10():\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    import torchvision\n",
        "    import torchvision.transforms as transforms\n",
        "\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "    class Net(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Net, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(3, 32, 3, 1)  # Output: (32, 30, 30)\n",
        "            self.pool = nn.MaxPool2d(2, 2)       # Output: (32, 15, 15)\n",
        "            self.conv2 = nn.Conv2d(32, 64, 3, 1) # Output: (64, 13, 13)\n",
        "            self.pool2 = nn.MaxPool2d(2, 2)      # Output: (64, 6, 6)\n",
        "            self.fc1 = nn.Linear(64 * 6 * 6, 128)\n",
        "            self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = torch.relu(self.conv1(x))\n",
        "            x = self.pool(x)\n",
        "            x = torch.relu(self.conv2(x))\n",
        "            x = self.pool2(x)\n",
        "            x = torch.flatten(x, 1)  # Flatten before FC layers\n",
        "            x = torch.relu(self.fc1(x))\n",
        "            x = self.fc2(x)\n",
        "            return x\n",
        "\n",
        "    net = Net().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(1):  # Single epoch training for quick testing\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if i % 100 == 0:\n",
        "                print(f'Epoch [{epoch+1}], Step [{i}], Loss: {loss.item():.4f}')\n",
        "\n",
        "train_cifar10()\n",
        "\n",
        "## 7️⃣ NVIDIA-SMI Utilization Monitoring\n",
        "## 8️⃣ Process-Specific GPU Monitoring\n",
        "!nvidia-smi pmon -i 0 -s um -c 10\n",
        "\n",
        "## 9️⃣ Power and Temperature Profiling\n",
        "!nvidia-smi --query-gpu=power.draw,power.limit,temperature.gpu --format=csv\n",
        "\n",
        "## 🔟 Run AI Workload & Observe Real-time Utilization\n",
        "x = torch.randn(10000, 10000, device=device)\n",
        "y = torch.randn(10000, 10000, device=device)\n",
        "print(\"Performing large matrix multiplication on GPU...\")\n",
        "%time z = torch.matmul(x, y)\n",
        "\n",
        "## 1️⃣1️⃣ Interfacing with Groq API for AI Processing\n",
        "import requests\n",
        "import json\n",
        "\n",
        "API_URL = \"https://api.groq.com/v1/chat/completions\"\n",
        "HEADERS = {\"Authorization\": \"Bearer YOUR_GROQ_API_KEY\", \"Content-Type\": \"application/json\"}\n",
        "\n",
        "def chat_with_groq(prompt):\n",
        "    payload = {\n",
        "        \"model\": \"llama3-8b-8192\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "    }\n",
        "    response = requests.post(API_URL, headers=HEADERS, data=json.dumps(payload))\n",
        "    return response.json()\n",
        "\n",
        "# Example Query to Groq API\n",
        "response = chat_with_groq(\"Explain how CUDA accelerates deep learning models.\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R40JJ8rh3elv",
        "outputId": "a422e4f2-0d5e-4ee9-90aa-760124a509ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar 11 11:08:56 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "✅ CUDA Available: True\n",
            "✅ CUDA Version: 12.4\n",
            "✅ cuDNN Version: 90300\n",
            "✅ TensorFlow GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "CPU times: user 17.7 ms, sys: 7.94 ms, total: 25.7 ms\n",
            "Wall time: 25.7 ms\n",
            "Files already downloaded and verified\n",
            "Epoch [1], Step [0], Loss: 2.3068\n",
            "Epoch [1], Step [100], Loss: 1.8716\n",
            "Epoch [1], Step [200], Loss: 1.3548\n",
            "Epoch [1], Step [300], Loss: 1.6989\n",
            "Epoch [1], Step [400], Loss: 1.4977\n",
            "Epoch [1], Step [500], Loss: 1.3103\n",
            "Epoch [1], Step [600], Loss: 1.1389\n",
            "Epoch [1], Step [700], Loss: 1.2372\n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "    0          -     -      -      -      -      -      -      -      -      -    -              \n",
            "power.draw [W], power.limit [W], temperature.gpu\n",
            "27.06 W, 70.00 W, 45\n",
            "Performing large matrix multiplication on GPU...\n",
            "CPU times: user 642 µs, sys: 0 ns, total: 642 µs\n",
            "Wall time: 651 µs\n",
            "{'error': {'message': 'Unknown request URL: POST /v1/chat/completions. Please check the URL for typos, or see the docs at https://console.groq.com/docs/', 'type': 'invalid_request_error', 'code': 'unknown_url'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zm7lbPCg4Me1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}